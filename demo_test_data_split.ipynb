{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T00:30:51.454212600Z",
     "start_time": "2024-07-24T00:30:49.862866900Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 168\u001B[0m\n\u001B[0;32m    166\u001B[0m WildScenesDataset\u001B[38;5;241m.\u001B[39mimage_file_base \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    167\u001B[0m WildScenesDataset\u001B[38;5;241m.\u001B[39mlabel_file_base \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindexLabel\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 168\u001B[0m \u001B[43mWildScenesDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_data_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 114\u001B[0m, in \u001B[0;36mWildScenesDataset.make_data_list\u001B[1;34m(train_rate, valid_rate, shuffle)\u001B[0m\n\u001B[0;32m    111\u001B[0m label_base \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindexLabel\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# Create DataFrame with image and label paths\u001B[39;00m\n\u001B[1;32m--> 114\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage_base\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_base\u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;66;03m# Sort DataFrame by filename (assumed to be timestamp in a sortable format)\u001B[39;00m\n\u001B[0;32m    119\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mint\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(x))[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]))\n",
      "File \u001B[1;32mE:\\Languages\\Anaconda3\\envs\\image_processing\\lib\\site-packages\\pandas\\core\\frame.py:778\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    772\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[0;32m    773\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    774\u001B[0m     )\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    777\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[1;32m--> 778\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "File \u001B[1;32mE:\\Languages\\Anaconda3\\envs\\image_processing\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    500\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[0;32m    501\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[1;32m--> 503\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Languages\\Anaconda3\\envs\\image_processing\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 114\u001B[0m         index \u001B[38;5;241m=\u001B[39m \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    116\u001B[0m         index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n",
      "File \u001B[1;32mE:\\Languages\\Anaconda3\\envs\\image_processing\\lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001B[0m, in \u001B[0;36m_extract_index\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    664\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPer-column arrays must each be 1-dimensional\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m indexes \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m raw_lengths:\n\u001B[1;32m--> 667\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf using all scalar values, you must pass an index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    669\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m have_series:\n\u001B[0;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m union_indexes(indexes)\n",
      "\u001B[1;31mValueError\u001B[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class WildScenesDataset:\n",
    "    root_dirs = [\n",
    "        os.path.join('..', 'data', 'WildScenes', 'WildScenes2d', 'V-01'),\n",
    "        os.path.join('..', 'data', 'WildScenes', 'WildScenes2d', 'V-02'),\n",
    "        os.path.join('..', 'data', 'WildScenes', 'WildScenes2d', 'V-03')\n",
    "    ]\n",
    "    _data_list_dir = os.path.join('datasets', 'data_list')\n",
    "    _csv_files = {\n",
    "        'train': os.path.join(_data_list_dir, 'train.csv'),\n",
    "        'valid': os.path.join(_data_list_dir, 'valid.csv'),\n",
    "        'test': os.path.join(_data_list_dir, 'test.csv'),\n",
    "    }\n",
    "    csv = _csv_files\n",
    "    _label_to_trainid = {\n",
    "        0: 15, 1: 16, 2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7,\n",
    "        10: 8, 11: 16, 12: 9, 13: 10, 14: 11, 15: 12, 16: 13, 17: 16, 18: 14,\n",
    "    }\n",
    "\n",
    "    def __init__(self, dataset_type, transform=None):\n",
    "        assert dataset_type in ('train', 'valid', 'test')\n",
    "        self._dataset_type = dataset_type\n",
    "        self._data_frame = pd.read_csv(WildScenesDataset._csv_files[self._dataset_type])\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            raise IndexError(f\"Index {index} out of bounds for dataset of size {len(self)}\")\n",
    "        \n",
    "        image_path = self._data_frame['image'].iloc[index]\n",
    "        label_path = self._data_frame['label'].iloc[index]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = Image.open(label_path).convert('L')\n",
    "        label_np = np.array(label)\n",
    "\n",
    "        label_trainId = np.vectorize(lambda x: self._label_to_trainid.get(x, 255))(label_np)\n",
    "\n",
    "        if self._transform is not None:\n",
    "            image, label_trainId = self._transform(image, label_trainId)\n",
    "\n",
    "        return image, label_trainId\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_distribution(label_path):\n",
    "        \"\"\"\n",
    "        Get the distribution of classes in a single label image.\n",
    "        \"\"\"\n",
    "        label = Image.open(label_path).convert('L')\n",
    "        label_np = np.array(label)\n",
    "        unique, counts = np.unique(label_np, return_counts=True)\n",
    "        return dict(zip(unique, counts))\n",
    "\n",
    "    @staticmethod\n",
    "    def print_class_distribution(df, set_name):\n",
    "        \"\"\"\n",
    "        Print the distribution of classes in a dataset.\n",
    "        \"\"\"\n",
    "        all_classes = Counter()\n",
    "        for dist in df['distribution']:\n",
    "            all_classes.update(dist)\n",
    "        \n",
    "        print(f\"\\nClass distribution in {set_name} set:\")\n",
    "        for class_id, count in all_classes.items():\n",
    "            print(f\"Class {class_id}: {count} pixels\")\n",
    "        \n",
    "        return all_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_class_distribution(train_dist, valid_dist, test_dist):\n",
    "        \"\"\"\n",
    "        Plot the distribution of classes across train, validation, and test sets.\n",
    "        \"\"\"\n",
    "        classes = sorted(set(train_dist.keys()) | set(valid_dist.keys()) | set(test_dist.keys()))\n",
    "        train_counts = [train_dist.get(c, 0) for c in classes]\n",
    "        valid_counts = [valid_dist.get(c, 0) for c in classes]\n",
    "        test_counts = [test_dist.get(c, 0) for c in classes]\n",
    "\n",
    "        x = np.arange(len(classes))\n",
    "        width = 0.25\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        ax.bar(x - width, train_counts, width, label='Train')\n",
    "        ax.bar(x, valid_counts, width, label='Validation')\n",
    "        ax.bar(x + width, test_counts, width, label='Test')\n",
    "\n",
    "        ax.set_ylabel('Pixel Count')\n",
    "        ax.set_title('Class Distribution Across Datasets')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(classes)\n",
    "        ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('class_distribution.png')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_data_list(train_rate=0.7, valid_rate=0.2):\n",
    "        \"\"\"\n",
    "        Generate data_list CSV files with stratified sampling and step-by-step output.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(WildScenesDataset._data_list_dir):\n",
    "            os.makedirs(WildScenesDataset._data_list_dir)\n",
    "\n",
    "        all_image_paths = []\n",
    "        all_label_paths = []\n",
    "        all_label_distributions = []\n",
    "\n",
    "        print(\"Step 1: Collecting image and label paths, and computing label distributions\")\n",
    "        for root_dir in WildScenesDataset.root_dirs:\n",
    "            image_base = os.path.join(root_dir, 'image')\n",
    "            label_base = os.path.join(root_dir, 'indexLabel')\n",
    "\n",
    "            if not os.path.exists(image_base) or not os.path.exists(label_base):\n",
    "                print(f\"Error: Image or label directory does not exist in {root_dir}\")\n",
    "                continue\n",
    "\n",
    "            for image in os.listdir(image_base):\n",
    "                image_path = os.path.join(image_base, image)\n",
    "                label_path = os.path.join(label_base, image)\n",
    "\n",
    "                if not (os.path.isfile(label_path) and os.path.exists(label_path)):\n",
    "                    print(f\"Warning: Skipping invalid file pair {image_path}, {label_path}\")\n",
    "                    continue\n",
    "\n",
    "                all_image_paths.append(image_path)\n",
    "                all_label_paths.append(label_path)\n",
    "                all_label_distributions.append(WildScenesDataset.get_label_distribution(label_path))\n",
    "\n",
    "        print(f\"Total images processed: {len(all_image_paths)}\")\n",
    "\n",
    "        print(\"\\nStep 2: Creating DataFrame with image paths, label paths, and distributions\")\n",
    "        df = pd.DataFrame({\n",
    "            'image': all_image_paths,\n",
    "            'label': all_label_paths,\n",
    "            'distribution': all_label_distributions\n",
    "        })\n",
    "\n",
    "        print(\"DataFrame shape:\", df.shape)\n",
    "        print(\"Sample of the DataFrame:\")\n",
    "        print(df.head())\n",
    "\n",
    "        print(\"\\nStep 3: Creating stratification column based on the most common class in each image\")\n",
    "        df['strat'] = df['distribution'].apply(lambda x: max(x, key=x.get))\n",
    "        print(\"Unique stratification values:\", df['strat'].unique())\n",
    "\n",
    "        print(\"\\nStep 4: Performing stratified split\")\n",
    "        train_valid, test = train_test_split(df, test_size=1-train_rate-valid_rate, stratify=df['strat'], random_state=42)\n",
    "        train, valid = train_test_split(train_valid, test_size=valid_rate/(train_rate+valid_rate), stratify=train_valid['strat'], random_state=42)\n",
    "\n",
    "        print('Total: {:d} | Train: {:d} | Validation: {:d} | Test: {:d}'.format(\n",
    "            len(df), len(train), len(valid), len(test)))\n",
    "\n",
    "        train_dist = WildScenesDataset.print_class_distribution(train, \"Train\")\n",
    "        valid_dist = WildScenesDataset.print_class_distribution(valid, \"Validation\")\n",
    "        test_dist = WildScenesDataset.print_class_distribution(test, \"Test\")\n",
    "\n",
    "        WildScenesDataset.plot_class_distribution(train_dist, valid_dist, test_dist)\n",
    "\n",
    "        print(\"\\nStep 5: Saving train, valid, and test sets to CSV files\")\n",
    "        train[['image', 'label']].to_csv(WildScenesDataset.csv['train'], index=False)\n",
    "        valid[['image', 'label']].to_csv(WildScenesDataset.csv['valid'], index=False)\n",
    "        test[['image', 'label']].to_csv(WildScenesDataset.csv['test'], index=False)\n",
    "        print(\"CSV files saved successfully.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Starting WildScenes dataset processing...\")\n",
    "    WildScenesDataset.make_data_list()\n",
    "    print(\"Dataset processing completed.\")\n",
    "\n",
    "    # Example usage of the dataset\n",
    "    print(\"\\nTesting dataset loading...\")\n",
    "    train_dataset = WildScenesDataset('train')\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    \n",
    "    # Load and display a sample image and label\n",
    "    sample_image, sample_label = train_dataset[0]\n",
    "    print(f\"Sample image shape: {np.array(sample_image).shape}\")\n",
    "    print(f\"Sample label shape: {sample_label.shape}\")\n",
    "    print(f\"Unique values in sample label: {np.unique(sample_label)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
