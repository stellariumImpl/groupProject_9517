{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744e400c-bc82-45a0-babc-cf1a8980f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3fe34e-d64c-4350-937c-f270bcb9f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildScenesDataset:\n",
    "    _data_list_dir = os.path.join('datasets', 'data_list')\n",
    "    _csv_files = {\n",
    "        'train': os.path.join(_data_list_dir, 'train.csv'),\n",
    "        'valid': os.path.join(_data_list_dir, 'valid.csv'),\n",
    "        'test': os.path.join(_data_list_dir, 'test.csv'),\n",
    "    }\n",
    "    csv = _csv_files\n",
    "    _label_to_trainid = {\n",
    "        0: 15,  # 背景类\n",
    "        1: 16,  # 忽略类\n",
    "        2: 0,  # Bush\n",
    "        3: 1,  # Dirt\n",
    "        4: 2,  # Fence\n",
    "        5: 3,  # Grass\n",
    "        6: 4,  # Gravel\n",
    "        7: 5,  # Log\n",
    "        8: 6,  # Mud\n",
    "        9: 7,  # Other-Object\n",
    "        10: 8,  # Other-terrain\n",
    "        11: 16,  # 忽略类\n",
    "        12: 9,  # Rock\n",
    "        13: 10,  # Sky\n",
    "        14: 11,  # Structure\n",
    "        15: 12,  # Tree-foliage\n",
    "        16: 13,  # Tree-trunk\n",
    "        17: 16,  # 忽略类\n",
    "        18: 14,  # Water\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def ensure_dir(directory):\n",
    "        \"\"\"确保目录存在，如果不存在则创建\"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "    def __init__(self, dataset_type, transform=None):\n",
    "        assert dataset_type in ('train', 'valid', 'test')\n",
    "        self._dataset_type = dataset_type\n",
    "        self._data_frame = pd.read_csv(WildScenesDataset._csv_files[self._dataset_type])\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data_frame)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            raise IndexError(f\"Index {index} out of bounds for dataset of size {len(self)}\")\n",
    "        try:\n",
    "            image_path = self._data_frame['image'].iloc[index]\n",
    "            label_path = self._data_frame['label'].iloc[index]\n",
    "\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = Image.open(label_path).convert('L')\n",
    "            # 将灰度图转换为Numpy数组\n",
    "            label_np = np.array(label)\n",
    "\n",
    "            # 将标签索引映射到训练标识（trainId）值\n",
    "            label_trainId = np.vectorize(lambda x: self._label_to_trainid.get(x, 255))(label_np)\n",
    "\n",
    "            if self._transform is not None:\n",
    "                for t in self._transform:\n",
    "                    image, label_trainId = t(image, label_trainId)\n",
    "\n",
    "            return image, label_trainId\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading item at index {index}: {str(e)}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_image_label_dir():\n",
    "        \"\"\"\n",
    "        Traverse server image and label directories and yield image and label paths.\n",
    "        :return: Generator yielding (image path, label path)\n",
    "        \"\"\"\n",
    "        data_err = 'data error. check!'\n",
    "        image_base = WildScenesDataset.image_file_base\n",
    "        label_base = WildScenesDataset.label_file_base\n",
    "\n",
    "        for image in os.listdir(image_base):\n",
    "            image_origin = os.path.join(image_base, image)\n",
    "            image_label = os.path.join(label_base, image)\n",
    "\n",
    "            if not (os.path.isfile(image_label) and\n",
    "                    os.path.exists(image_label) and\n",
    "                    os.path.isfile(image_label)):\n",
    "                print(image_origin, image_label, data_err)  # Print error message and skip if paths are invalid\n",
    "                continue\n",
    "\n",
    "            yield image_origin, image_label\n",
    "\n",
    "    @staticmethod\n",
    "    def make_data_list(train_rate=0.7, valid_rate=0.2, shuffle=True):\n",
    "        \"\"\"\n",
    "        Shuffle and generate data_list CSV files with image and label paths sorted by filename.\n",
    "        :param train_rate: Training set ratio, default 0.7\n",
    "        :param valid_rate: Validation set ratio, default 0.2\n",
    "        :param shuffle: Whether to shuffle the dataset, default True\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        WildScenesDataset.ensure_dir(WildScenesDataset._data_list_dir)  # 确保目录存在\n",
    "\n",
    "        g = WildScenesDataset._get_image_label_dir()  # Get generator\n",
    "        abspaths = list(g)  # Convert generator to list\n",
    "\n",
    "        # Create DataFrame with image and label paths\n",
    "        df = pd.DataFrame(\n",
    "            data=abspaths,\n",
    "            columns=['image', 'label']\n",
    "        )\n",
    "\n",
    "        # Sort DataFrame by filename (assumed to be timestamp in a sortable format)\n",
    "        df['timestamp'] = df['image'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0].split('-')[0]))\n",
    "        df = df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "        if shuffle:\n",
    "            df = sklearn.utils.shuffle(df)  # Shuffle dataframe if specified\n",
    "\n",
    "        # Calculate sizes for train, valid, and test sets\n",
    "        train_size = int(df.shape[0] * train_rate)\n",
    "        valid_size = int(df.shape[0] * valid_rate)\n",
    "\n",
    "        print('total: {:d} | train: {:d} | val: {:d} | test: {:d}'.format(\n",
    "            df.shape[0], train_size, valid_size,\n",
    "            df.shape[0] - train_size - valid_size))\n",
    "\n",
    "        # Split dataframe into train, valid, and test sets\n",
    "        df_train = df[0: train_size]\n",
    "        df_valid = df[train_size: train_size + valid_size]\n",
    "        df_test = df[train_size + valid_size:]\n",
    "\n",
    "        # Save train, valid, and test sets to CSV files\n",
    "        df_train[['image', 'label']].to_csv(os.path.join(WildScenesDataset.csv['train']), index=False)\n",
    "        df_valid[['image', 'label']].to_csv(os.path.join(WildScenesDataset.csv['valid']), index=False)\n",
    "        df_test[['image', 'label']].to_csv(os.path.join(WildScenesDataset.csv['test']), index=False)\n",
    "\n",
    "    # 测试語義分割時用\n",
    "    @staticmethod\n",
    "    def test_label_mapping(label_path):\n",
    "        \"\"\"\n",
    "        Test the label mapping for a single label image.\n",
    "\n",
    "        :param label_path: Path to the label image\n",
    "        :return: Tuple of original label numpy array and mapped trainId numpy array\n",
    "        \"\"\"\n",
    "        # Open the label image and convert to numpy array\n",
    "        label = Image.open(label_path).convert('L')\n",
    "        label_np = np.array(label, dtype=np.uint8)\n",
    "\n",
    "        # Map label indices to trainId values\n",
    "        label_trainId = np.vectorize(lambda x: WildScenesDataset._label_to_trainid.get(x, 255))(label_np)\n",
    "\n",
    "        return label_np, label_trainId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0419961-4611-4224-a02a-84f0dbce1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1576 | train: 1103 | val: 315 | test: 158\n",
      "Original label array (shape: (1512, 2016)):\n",
      "[[ 8  8  8 ...  8  8  8]\n",
      " [ 8  8  8 ...  8  8  8]\n",
      " [ 8  8  8 ...  8  8  8]\n",
      " ...\n",
      " [18 18 18 ...  2  2  2]\n",
      " [18 18 18 ...  2  2  2]\n",
      " [18 18 18 ...  2  2  2]]\n",
      "\n",
      "Mapped trainId array (shape: (1512, 2016)):\n",
      "[[ 6  6  6 ...  6  6  6]\n",
      " [ 6  6  6 ...  6  6  6]\n",
      " [ 6  6  6 ...  6  6  6]\n",
      " ...\n",
      " [14 14 14 ...  0  0  0]\n",
      " [14 14 14 ...  0  0  0]\n",
      " [14 14 14 ...  0  0  0]]\n",
      "\n",
      "Unique values in original label array: [ 2  7  8 14 15 16 17 18]\n",
      "Unique values in mapped trainId array: [ 0  5  6 11 12 13 14 16]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "root_dir = os.path.join('..', 'WildScenes_Dataset-61gd5a0t-', 'data', 'WildScenes', 'WildScenes2d', 'V-01')\n",
    "WildScenesDataset.image_file_base = os.path.join(root_dir, 'image')\n",
    "WildScenesDataset.label_file_base = os.path.join(root_dir, 'indexLabel')\n",
    "WildScenesDataset.make_data_list()\n",
    "\n",
    "# Test label mapping for the first image in labelIndex\n",
    "test_label_path = os.path.join(WildScenesDataset.label_file_base,\n",
    "                               '1623370408-092005506.png')  # Replace with an actual image name\n",
    "original_label, mapped_label = WildScenesDataset.test_label_mapping(test_label_path)\n",
    "\n",
    "print(\"Original label array (shape: {}):\".format(original_label.shape))\n",
    "print(original_label)\n",
    "print(\"\\nMapped trainId array (shape: {}):\".format(mapped_label.shape))\n",
    "print(mapped_label)\n",
    "\n",
    "# Optional: print unique values in each array\n",
    "print(\"\\nUnique values in original label array:\", np.unique(original_label))\n",
    "print(\"Unique values in mapped trainId array:\", np.unique(mapped_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a745324-5a12-4071-ba94-204443287e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional as TF\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "class TrainTransform:\n",
    "    def __init__(self, size=256, gaussian_prob=0.5, gaussian_kernel=(5, 5), gaussian_sigma=(0.1, 2.0)):\n",
    "        self.size = (size, size)  # Changed to tuple\n",
    "        self.gaussian_prob = gaussian_prob\n",
    "        self.gaussian_kernel = gaussian_kernel\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        # Resize\n",
    "        image = TF.resize(image, self.size)\n",
    "        label = TF.resize(label, self.size, interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            label = TF.hflip(label)\n",
    "\n",
    "        # Random rotation\n",
    "        angle = random.uniform(-10, 10)\n",
    "        image = TF.rotate(image, angle)\n",
    "        label = TF.rotate(label, angle, interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "        # Random Gaussian blur\n",
    "        if random.random() < self.gaussian_prob:\n",
    "            sigma = random.uniform(self.gaussian_sigma[0], self.gaussian_sigma[1])\n",
    "            image_np = np.array(image)\n",
    "            image_np = cv2.GaussianBlur(image_np, self.gaussian_kernel, sigma)\n",
    "            image = Image.fromarray(image_np)\n",
    "\n",
    "        # Convert to tensor and normalize\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        label = torch.from_numpy(np.array(label)).long()\n",
    "\n",
    "        # Verify shapes\n",
    "        assert image.shape[0] == 3, f\"Image should have 3 channels, got {image.shape[0]}\"\n",
    "        assert image.shape[1] == image.shape[2] == self.size[0], f\"Image should be square with size {self.size[0]}, got shape {image.shape}\"\n",
    "        assert label.shape == image.shape[1:], f\"Label shape {label.shape} doesn't match image shape {image.shape[1:]}\"\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class TestTransform:\n",
    "    def __init__(self, size=256):\n",
    "        self.size = (size, size)  # Changed to tuple\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        # Resize\n",
    "        image = TF.resize(image, self.size)\n",
    "        label = TF.resize(label, self.size, interpolation=TF.InterpolationMode.NEAREST)\n",
    "\n",
    "        # Convert to tensor and normalize\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        label = torch.from_numpy(np.array(label)).long()\n",
    "\n",
    "        # Verify shapes\n",
    "        assert image.shape[0] == 3, f\"Image should have 3 channels, got {image.shape[0]}\"\n",
    "        assert image.shape[1] == image.shape[2] == self.size[0], f\"Image should be square with size {self.size[0]}, got shape {image.shape}\"\n",
    "        assert label.shape == image.shape[1:], f\"Label shape {label.shape} doesn't match image shape {image.shape[1:]}\"\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e469c7c-4cb3-4f20-8dbe-36311444de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch image shape: torch.Size([4, 3, 256, 256])\n",
      "Batch label shape: torch.Size([4, 256, 256])\n",
      "Batch label unique values: tensor([ 0,  1,  2,  5,  6,  7, 12, 13, 14, 16])\n",
      "Color-coded label shape: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from data_split import WildScenesDataset\n",
    "from utils.transforms import TrainTransform, TestTransform\n",
    "\n",
    "color_map = {\n",
    "    0: [224, 31, 77],  # Bush\n",
    "    1: [64, 180, 78],  # Dirt\n",
    "    2: [26, 127, 127],  # Fence\n",
    "    3: [127, 127, 127],  # Grass\n",
    "    4: [145, 24, 178],  # Gravel\n",
    "    5: [125, 128, 16],  # Log\n",
    "    6: [251, 225, 48],  # Mud\n",
    "    7: [248, 190, 190],  # Other-object\n",
    "    8: [89, 239, 239],  # Other-terrain\n",
    "    9: [173, 255, 196],  # Rock\n",
    "    10: [19, 0, 126],  # Sky\n",
    "    11: [167, 110, 44],  # Structure\n",
    "    12: [208, 245, 71],  # Tree-foliage\n",
    "    13: [238, 47, 227],  # Tree-trunk\n",
    "    14: [40, 127, 198],  # Water\n",
    "    15: [0, 0, 0],      # 背景类（黑色）\n",
    "    16: [128, 128, 128],  # 忽略类（灰色）\n",
    "}\n",
    "\n",
    "class EnhancedWildScenesDataset(WildScenesDataset):\n",
    "    def __init__(self, dataset_type, transform=None):\n",
    "        super().__init__(dataset_type, transform)\n",
    "        self.color_map = self._load_color_map()\n",
    "        self.transform = self._get_transform(dataset_type)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self._data_frame['image'][index]\n",
    "        label_path = self._data_frame['label'][index]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        # Use test_label_mapping to get both original and mapped labels\n",
    "        original_label, mapped_label = self.test_label_mapping(label_path)\n",
    "\n",
    "        # Convert numpy array to PIL Image for compatibility with transforms\n",
    "        label = Image.fromarray(mapped_label.astype(np.uint8))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image, label = self.transform(image, label)\n",
    "\n",
    "        # Verify shapes\n",
    "        # assert image.shape[0] == 3, f\"Image should have 3 channels, got {image.shape[0]}\"\n",
    "        # assert image.shape[1] == image.shape[2], f\"Image should be square, got shape {image.shape}\"\n",
    "        # assert label.shape == image.shape[1:], f\"Label shape {label.shape} doesn't match image shape {image.shape[1:]}\"\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_color_map(self):\n",
    "        return {key: np.array(value) for key, value in color_map.items()}\n",
    "\n",
    "    def _get_transform(self, dataset_type):\n",
    "        if dataset_type == 'train':\n",
    "            return TrainTransform()\n",
    "        elif dataset_type in ['valid', 'test']:\n",
    "            return TestTransform()\n",
    "        else:\n",
    "            raise ValueError('Invalid dataset type')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_color_coded_label(label_trainId):\n",
    "        \"\"\"\n",
    "        Convert trainId label to RGB color-coded label.\n",
    "        :param label_trainId: numpy array of trainId labels\n",
    "        :return: numpy array of RGB color-coded labels\n",
    "        \"\"\"\n",
    "        height, width = label_trainId.shape\n",
    "        label_RGB = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        for trainId, color in color_map.items():\n",
    "            label_RGB[label_trainId == trainId] = color\n",
    "        return label_RGB\n",
    "\n",
    "def get_data_loader(dataset_type, batch_size=4):\n",
    "    dataset = EnhancedWildScenesDataset(dataset_type)\n",
    "    shuffle = dataset_type == 'train'\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "# 测试data_loader\n",
    "train_loader = get_data_loader('train', batch_size=4)\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch image shape: {images.shape}\") # 一個批次的圖像數據形狀，一個批次4個圖象，每個圖象3通道，每個圖像尺寸256*341\n",
    "    print(f\"Batch label shape: {labels.shape}\") # 一個批次的label數據形狀，單通道，表示的是trainId標注的\n",
    "    print(f\"Batch label unique values: {torch.unique(labels)}\")\n",
    "    break\n",
    "\n",
    "dataset = EnhancedWildScenesDataset('train')\n",
    "image, label = dataset[0]\n",
    "color_coded_label = dataset.get_color_coded_label(label.numpy())\n",
    "print(f\"Color-coded label shape: {color_coded_label.shape}\") # 使用顔色編碼的label圖像形狀，發現是3通道，成了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc213349-8960-40ef-8829-c966fc6f5f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 14:19:29,035 - INFO - Using device: cuda\n",
      "2024-07-15 14:19:29,624 - INFO - Epoch 1/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:10<00:00,  3.15s/it]\n",
      "2024-07-15 14:26:40,590 - INFO - Epoch 1 - Train Loss: 0.8442, Train mIoU: 0.5946, Train Pixel Acc: 0.7653, Train Dice: 0.6317\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:58<00:00,  3.03s/it]\n",
      "2024-07-15 14:28:38,886 - INFO - Epoch 1 - Val Loss: 0.6269, Val mIoU: 0.6499, Val Pixel Acc: 0.8248, Val Dice: 0.6840\n",
      "2024-07-15 14:28:39,423 - INFO - Epoch 1 - Best model saved with mIoU: 0.6499\n",
      "2024-07-15 14:28:39,423 - INFO - Current learning rate: 0.000473\n",
      "2024-07-15 14:28:39,424 - INFO - Epoch 2/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:09<00:00,  3.13s/it]\n",
      "2024-07-15 14:35:48,867 - INFO - Epoch 2 - Train Loss: 0.6338, Train mIoU: 0.6359, Train Pixel Acc: 0.8139, Train Dice: 0.6728\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.02s/it]\n",
      "2024-07-15 14:37:46,718 - INFO - Epoch 2 - Val Loss: 0.6211, Val mIoU: 0.6555, Val Pixel Acc: 0.8116, Val Dice: 0.6945\n",
      "2024-07-15 14:37:47,275 - INFO - Epoch 2 - Best model saved with mIoU: 0.6555\n",
      "2024-07-15 14:37:47,276 - INFO - Current learning rate: 0.000690\n",
      "2024-07-15 14:37:47,277 - INFO - Epoch 3/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:10<00:00,  3.14s/it]\n",
      "2024-07-15 14:44:57,432 - INFO - Epoch 3 - Train Loss: 0.6199, Train mIoU: 0.6381, Train Pixel Acc: 0.8174, Train Dice: 0.6755\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.02s/it]\n",
      "2024-07-15 14:46:55,146 - INFO - Epoch 3 - Val Loss: 0.5957, Val mIoU: 0.6551, Val Pixel Acc: 0.8306, Val Dice: 0.6940\n",
      "2024-07-15 14:46:55,146 - INFO - Current learning rate: 0.001044\n",
      "2024-07-15 14:46:55,147 - INFO - Epoch 4/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:11<00:00,  3.15s/it]\n",
      "2024-07-15 14:54:06,293 - INFO - Epoch 4 - Train Loss: 0.6198, Train mIoU: 0.6331, Train Pixel Acc: 0.8154, Train Dice: 0.6719\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.02s/it]\n",
      "2024-07-15 14:56:04,206 - INFO - Epoch 4 - Val Loss: 0.6409, Val mIoU: 0.6474, Val Pixel Acc: 0.7872, Val Dice: 0.6930\n",
      "2024-07-15 14:56:04,207 - INFO - Current learning rate: 0.001524\n",
      "2024-07-15 14:56:04,207 - INFO - Epoch 5/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:08<00:00,  3.13s/it]\n",
      "2024-07-15 15:03:12,559 - INFO - Epoch 5 - Train Loss: 0.5967, Train mIoU: 0.6254, Train Pixel Acc: 0.7991, Train Dice: 0.6646\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:58<00:00,  3.03s/it]\n",
      "2024-07-15 15:05:10,625 - INFO - Epoch 5 - Val Loss: 0.7117, Val mIoU: 0.5928, Val Pixel Acc: 0.6909, Val Dice: 0.6381\n",
      "2024-07-15 15:05:11,159 - INFO - Epoch 5 - Checkpoint saved\n",
      "2024-07-15 15:05:11,160 - INFO - Current learning rate: 0.002116\n",
      "2024-07-15 15:05:11,161 - INFO - Epoch 6/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:11<00:00,  3.15s/it]\n",
      "2024-07-15 15:12:22,370 - INFO - Epoch 6 - Train Loss: 0.4598, Train mIoU: 0.6246, Train Pixel Acc: 0.8078, Train Dice: 0.6646\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 15:14:19,450 - INFO - Epoch 6 - Val Loss: 0.4546, Val mIoU: 0.6453, Val Pixel Acc: 0.8159, Val Dice: 0.6856\n",
      "2024-07-15 15:14:19,450 - INFO - Current learning rate: 0.002802\n",
      "2024-07-15 15:14:19,451 - INFO - Epoch 7/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:10<00:00,  3.15s/it]\n",
      "2024-07-15 15:21:30,444 - INFO - Epoch 7 - Train Loss: 0.4800, Train mIoU: 0.6157, Train Pixel Acc: 0.7972, Train Dice: 0.6553\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:58<00:00,  3.03s/it]\n",
      "2024-07-15 15:23:28,471 - INFO - Epoch 7 - Val Loss: 0.4828, Val mIoU: 0.6386, Val Pixel Acc: 0.7716, Val Dice: 0.6862\n",
      "2024-07-15 15:23:28,472 - INFO - Current learning rate: 0.003561\n",
      "2024-07-15 15:23:28,472 - INFO - Epoch 8/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:13<00:00,  3.16s/it]\n",
      "2024-07-15 15:30:41,613 - INFO - Epoch 8 - Train Loss: 0.4427, Train mIoU: 0.6261, Train Pixel Acc: 0.8050, Train Dice: 0.6668\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.02s/it]\n",
      "2024-07-15 15:32:39,507 - INFO - Epoch 8 - Val Loss: 0.4250, Val mIoU: 0.6544, Val Pixel Acc: 0.7973, Val Dice: 0.7026\n",
      "2024-07-15 15:32:39,507 - INFO - Current learning rate: 0.004369\n",
      "2024-07-15 15:32:39,507 - INFO - Epoch 9/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:08<00:00,  3.13s/it]\n",
      "2024-07-15 15:39:48,054 - INFO - Epoch 9 - Train Loss: 0.4287, Train mIoU: 0.6361, Train Pixel Acc: 0.8096, Train Dice: 0.6768\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.01s/it]\n",
      "2024-07-15 15:41:45,536 - INFO - Epoch 9 - Val Loss: 0.4293, Val mIoU: 0.6452, Val Pixel Acc: 0.7832, Val Dice: 0.6878\n",
      "2024-07-15 15:41:45,536 - INFO - Current learning rate: 0.005203\n",
      "2024-07-15 15:41:45,536 - INFO - Epoch 10/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:06<00:00,  3.12s/it]\n",
      "2024-07-15 15:48:52,338 - INFO - Epoch 10 - Train Loss: 0.4621, Train mIoU: 0.6268, Train Pixel Acc: 0.7927, Train Dice: 0.6664\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.02s/it]\n",
      "2024-07-15 15:50:50,178 - INFO - Epoch 10 - Val Loss: 0.4699, Val mIoU: 0.6266, Val Pixel Acc: 0.7896, Val Dice: 0.6626\n",
      "2024-07-15 15:50:51,179 - INFO - Epoch 10 - Checkpoint saved\n",
      "2024-07-15 15:50:51,181 - INFO - Current learning rate: 0.006037\n",
      "2024-07-15 15:50:51,181 - INFO - Epoch 11/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:05<00:00,  3.11s/it]\n",
      "2024-07-15 15:57:56,587 - INFO - Epoch 11 - Train Loss: 0.4371, Train mIoU: 0.6301, Train Pixel Acc: 0.8061, Train Dice: 0.6689\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:58<00:00,  3.03s/it]\n",
      "2024-07-15 15:59:54,675 - INFO - Epoch 11 - Val Loss: 0.5222, Val mIoU: 0.6209, Val Pixel Acc: 0.7640, Val Dice: 0.6628\n",
      "2024-07-15 15:59:54,675 - INFO - Current learning rate: 0.006845\n",
      "2024-07-15 15:59:54,676 - INFO - Epoch 12/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:04<00:00,  3.10s/it]\n",
      "2024-07-15 16:06:59,545 - INFO - Epoch 12 - Train Loss: 0.4527, Train mIoU: 0.6263, Train Pixel Acc: 0.7982, Train Dice: 0.6653\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.01s/it]\n",
      "2024-07-15 16:08:56,870 - INFO - Epoch 12 - Val Loss: 0.4321, Val mIoU: 0.6314, Val Pixel Acc: 0.8029, Val Dice: 0.6720\n",
      "2024-07-15 16:08:56,870 - INFO - Current learning rate: 0.007604\n",
      "2024-07-15 16:08:56,870 - INFO - Epoch 13/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:09<00:00,  3.13s/it]\n",
      "2024-07-15 16:16:06,074 - INFO - Epoch 13 - Train Loss: 0.4207, Train mIoU: 0.6325, Train Pixel Acc: 0.8158, Train Dice: 0.6716\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.98s/it]\n",
      "2024-07-15 16:18:02,385 - INFO - Epoch 13 - Val Loss: 0.4096, Val mIoU: 0.6539, Val Pixel Acc: 0.8145, Val Dice: 0.6965\n",
      "2024-07-15 16:18:02,386 - INFO - Current learning rate: 0.008289\n",
      "2024-07-15 16:18:02,387 - INFO - Epoch 14/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:05<00:00,  3.11s/it]\n",
      "2024-07-15 16:25:08,288 - INFO - Epoch 14 - Train Loss: 0.4081, Train mIoU: 0.6396, Train Pixel Acc: 0.8200, Train Dice: 0.6798\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:58<00:00,  3.04s/it]\n",
      "2024-07-15 16:27:06,754 - INFO - Epoch 14 - Val Loss: 0.4076, Val mIoU: 0.6266, Val Pixel Acc: 0.8239, Val Dice: 0.6675\n",
      "2024-07-15 16:27:06,755 - INFO - Current learning rate: 0.008880\n",
      "2024-07-15 16:27:06,755 - INFO - Epoch 15/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:03<00:00,  3.09s/it]\n",
      "2024-07-15 16:34:10,342 - INFO - Epoch 15 - Train Loss: 0.4590, Train mIoU: 0.6305, Train Pixel Acc: 0.7882, Train Dice: 0.6701\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 16:36:07,334 - INFO - Epoch 15 - Val Loss: 0.6560, Val mIoU: 0.5935, Val Pixel Acc: 0.6005, Val Dice: 0.6382\n",
      "2024-07-15 16:36:07,860 - INFO - Epoch 15 - Checkpoint saved\n",
      "2024-07-15 16:36:07,860 - INFO - Current learning rate: 0.009359\n",
      "2024-07-15 16:36:07,860 - INFO - Epoch 16/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 16:43:09,753 - INFO - Epoch 16 - Train Loss: 0.4140, Train mIoU: 0.6459, Train Pixel Acc: 0.8138, Train Dice: 0.6846\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 16:45:06,577 - INFO - Epoch 16 - Val Loss: 0.4442, Val mIoU: 0.6500, Val Pixel Acc: 0.7708, Val Dice: 0.6946\n",
      "2024-07-15 16:45:06,577 - INFO - Current learning rate: 0.009712\n",
      "2024-07-15 16:45:06,577 - INFO - Epoch 17/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.07s/it]\n",
      "2024-07-15 16:52:07,618 - INFO - Epoch 17 - Train Loss: 0.4022, Train mIoU: 0.6487, Train Pixel Acc: 0.8177, Train Dice: 0.6887\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 16:54:04,416 - INFO - Epoch 17 - Val Loss: 0.3999, Val mIoU: 0.6569, Val Pixel Acc: 0.7999, Val Dice: 0.7015\n",
      "2024-07-15 16:54:04,933 - INFO - Epoch 17 - Best model saved with mIoU: 0.6569\n",
      "2024-07-15 16:54:04,933 - INFO - Current learning rate: 0.009928\n",
      "2024-07-15 16:54:04,933 - INFO - Epoch 18/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 17:01:05,779 - INFO - Epoch 18 - Train Loss: 0.3935, Train mIoU: 0.6474, Train Pixel Acc: 0.8219, Train Dice: 0.6877\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 17:03:02,642 - INFO - Epoch 18 - Val Loss: 0.3812, Val mIoU: 0.6507, Val Pixel Acc: 0.8210, Val Dice: 0.6902\n",
      "2024-07-15 17:03:02,642 - INFO - Current learning rate: 0.010000\n",
      "2024-07-15 17:03:02,642 - INFO - Epoch 19/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.07s/it]\n",
      "2024-07-15 17:10:03,895 - INFO - Epoch 19 - Train Loss: 0.4695, Train mIoU: 0.6238, Train Pixel Acc: 0.7766, Train Dice: 0.6637\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 17:12:00,974 - INFO - Epoch 19 - Val Loss: 0.4897, Val mIoU: 0.6205, Val Pixel Acc: 0.7690, Val Dice: 0.6599\n",
      "2024-07-15 17:12:00,974 - INFO - Current learning rate: 0.009986\n",
      "2024-07-15 17:12:00,989 - INFO - Epoch 20/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.05s/it]\n",
      "2024-07-15 17:18:59,522 - INFO - Epoch 20 - Train Loss: 0.4225, Train mIoU: 0.6366, Train Pixel Acc: 0.8061, Train Dice: 0.6745\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 17:20:55,955 - INFO - Epoch 20 - Val Loss: 0.4061, Val mIoU: 0.6405, Val Pixel Acc: 0.8043, Val Dice: 0.6840\n",
      "2024-07-15 17:20:56,472 - INFO - Epoch 20 - Checkpoint saved\n",
      "2024-07-15 17:20:56,472 - INFO - Current learning rate: 0.009944\n",
      "2024-07-15 17:20:56,472 - INFO - Epoch 21/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 17:27:56,680 - INFO - Epoch 21 - Train Loss: 0.4040, Train mIoU: 0.6456, Train Pixel Acc: 0.8161, Train Dice: 0.6855\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 17:29:53,461 - INFO - Epoch 21 - Val Loss: 0.3680, Val mIoU: 0.6630, Val Pixel Acc: 0.8323, Val Dice: 0.7038\n",
      "2024-07-15 17:29:53,998 - INFO - Epoch 21 - Best model saved with mIoU: 0.6630\n",
      "2024-07-15 17:29:54,013 - INFO - Current learning rate: 0.009874\n",
      "2024-07-15 17:29:54,013 - INFO - Epoch 22/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 17:36:53,807 - INFO - Epoch 22 - Train Loss: 0.3892, Train mIoU: 0.6535, Train Pixel Acc: 0.8220, Train Dice: 0.6945\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 17:38:50,903 - INFO - Epoch 22 - Val Loss: 0.3786, Val mIoU: 0.6640, Val Pixel Acc: 0.8293, Val Dice: 0.7051\n",
      "2024-07-15 17:38:51,434 - INFO - Epoch 22 - Best model saved with mIoU: 0.6640\n",
      "2024-07-15 17:38:51,450 - INFO - Current learning rate: 0.009777\n",
      "2024-07-15 17:38:51,450 - INFO - Epoch 23/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 17:45:50,632 - INFO - Epoch 23 - Train Loss: 0.3805, Train mIoU: 0.6522, Train Pixel Acc: 0.8243, Train Dice: 0.6934\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 17:47:47,280 - INFO - Epoch 23 - Val Loss: 0.3797, Val mIoU: 0.6682, Val Pixel Acc: 0.8196, Val Dice: 0.7141\n",
      "2024-07-15 17:47:47,780 - INFO - Epoch 23 - Best model saved with mIoU: 0.6682\n",
      "2024-07-15 17:47:47,780 - INFO - Current learning rate: 0.009653\n",
      "2024-07-15 17:47:47,780 - INFO - Epoch 24/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.06s/it]\n",
      "2024-07-15 17:54:46,491 - INFO - Epoch 24 - Train Loss: 0.4180, Train mIoU: 0.6462, Train Pixel Acc: 0.8078, Train Dice: 0.6864\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 17:56:43,383 - INFO - Epoch 24 - Val Loss: 0.4025, Val mIoU: 0.6599, Val Pixel Acc: 0.8099, Val Dice: 0.7064\n",
      "2024-07-15 17:56:43,383 - INFO - Current learning rate: 0.009504\n",
      "2024-07-15 17:56:43,383 - INFO - Epoch 25/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 18:03:43,146 - INFO - Epoch 25 - Train Loss: 0.3909, Train mIoU: 0.6507, Train Pixel Acc: 0.8208, Train Dice: 0.6914\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 18:05:39,752 - INFO - Epoch 25 - Val Loss: 0.3727, Val mIoU: 0.6676, Val Pixel Acc: 0.8302, Val Dice: 0.7106\n",
      "2024-07-15 18:05:40,877 - INFO - Epoch 25 - Checkpoint saved\n",
      "2024-07-15 18:05:40,877 - INFO - Current learning rate: 0.009329\n",
      "2024-07-15 18:05:40,882 - INFO - Epoch 26/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 18:12:40,564 - INFO - Epoch 26 - Train Loss: 0.3801, Train mIoU: 0.6568, Train Pixel Acc: 0.8257, Train Dice: 0.6994\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 18:14:37,066 - INFO - Epoch 26 - Val Loss: 0.4012, Val mIoU: 0.6631, Val Pixel Acc: 0.7872, Val Dice: 0.7090\n",
      "2024-07-15 18:14:37,066 - INFO - Current learning rate: 0.009130\n",
      "2024-07-15 18:14:37,066 - INFO - Epoch 27/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 18:21:36,423 - INFO - Epoch 27 - Train Loss: 0.3746, Train mIoU: 0.6601, Train Pixel Acc: 0.8277, Train Dice: 0.7017\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 18:23:33,436 - INFO - Epoch 27 - Val Loss: 0.3884, Val mIoU: 0.6637, Val Pixel Acc: 0.8166, Val Dice: 0.7103\n",
      "2024-07-15 18:23:33,436 - INFO - Current learning rate: 0.008907\n",
      "2024-07-15 18:23:33,436 - INFO - Epoch 28/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 18:30:33,792 - INFO - Epoch 28 - Train Loss: 0.3701, Train mIoU: 0.6593, Train Pixel Acc: 0.8280, Train Dice: 0.7018\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 18:32:30,709 - INFO - Epoch 28 - Val Loss: 0.3558, Val mIoU: 0.6660, Val Pixel Acc: 0.8362, Val Dice: 0.7059\n",
      "2024-07-15 18:32:30,709 - INFO - Current learning rate: 0.008663\n",
      "2024-07-15 18:32:30,709 - INFO - Epoch 29/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 18:39:31,401 - INFO - Epoch 29 - Train Loss: 0.3681, Train mIoU: 0.6610, Train Pixel Acc: 0.8290, Train Dice: 0.7034\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 18:41:28,318 - INFO - Epoch 29 - Val Loss: 0.3511, Val mIoU: 0.6775, Val Pixel Acc: 0.8329, Val Dice: 0.7222\n",
      "2024-07-15 18:41:28,833 - INFO - Epoch 29 - Best model saved with mIoU: 0.6775\n",
      "2024-07-15 18:41:28,833 - INFO - Current learning rate: 0.008399\n",
      "2024-07-15 18:41:28,836 - INFO - Epoch 30/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 18:48:28,920 - INFO - Epoch 30 - Train Loss: 0.3682, Train mIoU: 0.6592, Train Pixel Acc: 0.8293, Train Dice: 0.7022\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 18:50:25,730 - INFO - Epoch 30 - Val Loss: 0.3755, Val mIoU: 0.6575, Val Pixel Acc: 0.8220, Val Dice: 0.6988\n",
      "2024-07-15 18:50:26,247 - INFO - Epoch 30 - Checkpoint saved\n",
      "2024-07-15 18:50:26,247 - INFO - Current learning rate: 0.008115\n",
      "2024-07-15 18:50:26,247 - INFO - Epoch 31/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.06s/it]\n",
      "2024-07-15 18:57:24,984 - INFO - Epoch 31 - Train Loss: 0.3609, Train mIoU: 0.6660, Train Pixel Acc: 0.8322, Train Dice: 0.7095\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 18:59:21,886 - INFO - Epoch 31 - Val Loss: 0.3665, Val mIoU: 0.6714, Val Pixel Acc: 0.8290, Val Dice: 0.7151\n",
      "2024-07-15 18:59:21,886 - INFO - Current learning rate: 0.007814\n",
      "2024-07-15 18:59:21,886 - INFO - Epoch 32/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.05s/it]\n",
      "2024-07-15 19:06:20,013 - INFO - Epoch 32 - Train Loss: 0.3662, Train mIoU: 0.6635, Train Pixel Acc: 0.8313, Train Dice: 0.7063\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 19:08:16,995 - INFO - Epoch 32 - Val Loss: 0.3723, Val mIoU: 0.6614, Val Pixel Acc: 0.8142, Val Dice: 0.7061\n",
      "2024-07-15 19:08:16,995 - INFO - Current learning rate: 0.007498\n",
      "2024-07-15 19:08:16,995 - INFO - Epoch 33/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 19:15:17,262 - INFO - Epoch 33 - Train Loss: 0.3594, Train mIoU: 0.6605, Train Pixel Acc: 0.8329, Train Dice: 0.7043\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 19:17:14,077 - INFO - Epoch 33 - Val Loss: 0.3606, Val mIoU: 0.6681, Val Pixel Acc: 0.8324, Val Dice: 0.7098\n",
      "2024-07-15 19:17:14,077 - INFO - Current learning rate: 0.007167\n",
      "2024-07-15 19:17:14,077 - INFO - Epoch 34/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 19:24:13,201 - INFO - Epoch 34 - Train Loss: 0.3614, Train mIoU: 0.6634, Train Pixel Acc: 0.8313, Train Dice: 0.7069\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 19:26:10,149 - INFO - Epoch 34 - Val Loss: 0.3686, Val mIoU: 0.6694, Val Pixel Acc: 0.8189, Val Dice: 0.7150\n",
      "2024-07-15 19:26:10,149 - INFO - Current learning rate: 0.006824\n",
      "2024-07-15 19:26:10,149 - INFO - Epoch 35/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 19:33:11,535 - INFO - Epoch 35 - Train Loss: 0.3516, Train mIoU: 0.6673, Train Pixel Acc: 0.8345, Train Dice: 0.7131\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 19:35:07,977 - INFO - Epoch 35 - Val Loss: 0.3438, Val mIoU: 0.6860, Val Pixel Acc: 0.8376, Val Dice: 0.7320\n",
      "2024-07-15 19:35:08,492 - INFO - Epoch 35 - Best model saved with mIoU: 0.6860\n",
      "2024-07-15 19:35:09,013 - INFO - Epoch 35 - Checkpoint saved\n",
      "2024-07-15 19:35:09,017 - INFO - Current learning rate: 0.006471\n",
      "2024-07-15 19:35:09,017 - INFO - Epoch 36/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.07s/it]\n",
      "2024-07-15 19:42:10,104 - INFO - Epoch 36 - Train Loss: 0.3543, Train mIoU: 0.6610, Train Pixel Acc: 0.8339, Train Dice: 0.7060\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 19:44:06,667 - INFO - Epoch 36 - Val Loss: 0.3408, Val mIoU: 0.6841, Val Pixel Acc: 0.8388, Val Dice: 0.7305\n",
      "2024-07-15 19:44:06,667 - INFO - Current learning rate: 0.006110\n",
      "2024-07-15 19:44:06,667 - INFO - Epoch 37/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 19:51:08,022 - INFO - Epoch 37 - Train Loss: 0.3476, Train mIoU: 0.6657, Train Pixel Acc: 0.8360, Train Dice: 0.7112\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 19:53:05,059 - INFO - Epoch 37 - Val Loss: 0.3569, Val mIoU: 0.6719, Val Pixel Acc: 0.8309, Val Dice: 0.7164\n",
      "2024-07-15 19:53:05,065 - INFO - Current learning rate: 0.005743\n",
      "2024-07-15 19:53:05,065 - INFO - Epoch 38/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:04<00:00,  3.10s/it]\n",
      "2024-07-15 20:00:09,267 - INFO - Epoch 38 - Train Loss: 0.3515, Train mIoU: 0.6719, Train Pixel Acc: 0.8349, Train Dice: 0.7178\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 20:02:06,239 - INFO - Epoch 38 - Val Loss: 0.3444, Val mIoU: 0.6783, Val Pixel Acc: 0.8373, Val Dice: 0.7227\n",
      "2024-07-15 20:02:06,239 - INFO - Current learning rate: 0.005371\n",
      "2024-07-15 20:02:06,239 - INFO - Epoch 39/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:02<00:00,  3.08s/it]\n",
      "2024-07-15 20:09:08,800 - INFO - Epoch 39 - Train Loss: 0.3434, Train mIoU: 0.6679, Train Pixel Acc: 0.8373, Train Dice: 0.7132\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 20:11:05,552 - INFO - Epoch 39 - Val Loss: 0.3377, Val mIoU: 0.6883, Val Pixel Acc: 0.8370, Val Dice: 0.7377\n",
      "2024-07-15 20:11:06,098 - INFO - Epoch 39 - Best model saved with mIoU: 0.6883\n",
      "2024-07-15 20:11:06,098 - INFO - Current learning rate: 0.004997\n",
      "2024-07-15 20:11:06,100 - INFO - Epoch 40/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:02<00:00,  3.08s/it]\n",
      "2024-07-15 20:18:08,250 - INFO - Epoch 40 - Train Loss: 0.3349, Train mIoU: 0.6777, Train Pixel Acc: 0.8382, Train Dice: 0.7247\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 20:20:05,187 - INFO - Epoch 40 - Val Loss: 0.3619, Val mIoU: 0.6789, Val Pixel Acc: 0.8261, Val Dice: 0.7251\n",
      "2024-07-15 20:20:05,700 - INFO - Epoch 40 - Checkpoint saved\n",
      "2024-07-15 20:20:05,701 - INFO - Current learning rate: 0.004624\n",
      "2024-07-15 20:20:05,702 - INFO - Epoch 41/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:04<00:00,  3.10s/it]\n",
      "2024-07-15 20:27:10,175 - INFO - Epoch 41 - Train Loss: 0.3363, Train mIoU: 0.6719, Train Pixel Acc: 0.8408, Train Dice: 0.7200\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 20:29:07,218 - INFO - Epoch 41 - Val Loss: 0.3314, Val mIoU: 0.6894, Val Pixel Acc: 0.8392, Val Dice: 0.7385\n",
      "2024-07-15 20:29:07,726 - INFO - Epoch 41 - Best model saved with mIoU: 0.6894\n",
      "2024-07-15 20:29:07,736 - INFO - Current learning rate: 0.004252\n",
      "2024-07-15 20:29:07,736 - INFO - Epoch 42/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:02<00:00,  3.08s/it]\n",
      "2024-07-15 20:36:09,803 - INFO - Epoch 42 - Train Loss: 0.3285, Train mIoU: 0.6761, Train Pixel Acc: 0.8412, Train Dice: 0.7246\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 20:38:06,259 - INFO - Epoch 42 - Val Loss: 0.3303, Val mIoU: 0.6847, Val Pixel Acc: 0.8419, Val Dice: 0.7334\n",
      "2024-07-15 20:38:06,259 - INFO - Current learning rate: 0.003885\n",
      "2024-07-15 20:38:06,259 - INFO - Epoch 43/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 20:45:07,637 - INFO - Epoch 43 - Train Loss: 0.3362, Train mIoU: 0.6757, Train Pixel Acc: 0.8381, Train Dice: 0.7236\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 20:47:04,484 - INFO - Epoch 43 - Val Loss: 0.3475, Val mIoU: 0.6824, Val Pixel Acc: 0.8348, Val Dice: 0.7310\n",
      "2024-07-15 20:47:04,484 - INFO - Current learning rate: 0.003524\n",
      "2024-07-15 20:47:04,484 - INFO - Epoch 44/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 20:54:04,632 - INFO - Epoch 44 - Train Loss: 0.3277, Train mIoU: 0.6781, Train Pixel Acc: 0.8425, Train Dice: 0.7269\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.01s/it]\n",
      "2024-07-15 20:56:02,138 - INFO - Epoch 44 - Val Loss: 0.3292, Val mIoU: 0.6920, Val Pixel Acc: 0.8398, Val Dice: 0.7396\n",
      "2024-07-15 20:56:03,103 - INFO - Epoch 44 - Best model saved with mIoU: 0.6920\n",
      "2024-07-15 20:56:03,103 - INFO - Current learning rate: 0.003171\n",
      "2024-07-15 20:56:03,103 - INFO - Epoch 45/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.07s/it]\n",
      "2024-07-15 21:03:03,048 - INFO - Epoch 45 - Train Loss: 0.3216, Train mIoU: 0.6833, Train Pixel Acc: 0.8427, Train Dice: 0.7329\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 21:04:59,986 - INFO - Epoch 45 - Val Loss: 0.3395, Val mIoU: 0.6919, Val Pixel Acc: 0.8310, Val Dice: 0.7438\n",
      "2024-07-15 21:05:00,494 - INFO - Epoch 45 - Checkpoint saved\n",
      "2024-07-15 21:05:00,494 - INFO - Current learning rate: 0.002828\n",
      "2024-07-15 21:05:00,494 - INFO - Epoch 46/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.07s/it]\n",
      "2024-07-15 21:12:01,709 - INFO - Epoch 46 - Train Loss: 0.3158, Train mIoU: 0.6831, Train Pixel Acc: 0.8437, Train Dice: 0.7343\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 21:13:58,610 - INFO - Epoch 46 - Val Loss: 0.3212, Val mIoU: 0.6973, Val Pixel Acc: 0.8444, Val Dice: 0.7469\n",
      "2024-07-15 21:13:59,111 - INFO - Epoch 46 - Best model saved with mIoU: 0.6973\n",
      "2024-07-15 21:13:59,111 - INFO - Current learning rate: 0.002498\n",
      "2024-07-15 21:13:59,111 - INFO - Epoch 47/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.06s/it]\n",
      "2024-07-15 21:20:57,928 - INFO - Epoch 47 - Train Loss: 0.3065, Train mIoU: 0.6894, Train Pixel Acc: 0.8469, Train Dice: 0.7405\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 21:22:54,420 - INFO - Epoch 47 - Val Loss: 0.3318, Val mIoU: 0.6928, Val Pixel Acc: 0.8326, Val Dice: 0.7470\n",
      "2024-07-15 21:22:54,420 - INFO - Current learning rate: 0.002181\n",
      "2024-07-15 21:22:54,420 - INFO - Epoch 48/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:57<00:00,  3.05s/it]\n",
      "2024-07-15 21:29:51,967 - INFO - Epoch 48 - Train Loss: 0.3014, Train mIoU: 0.6944, Train Pixel Acc: 0.8484, Train Dice: 0.7468\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 21:31:48,539 - INFO - Epoch 48 - Val Loss: 0.3219, Val mIoU: 0.6964, Val Pixel Acc: 0.8459, Val Dice: 0.7463\n",
      "2024-07-15 21:31:48,539 - INFO - Current learning rate: 0.001881\n",
      "2024-07-15 21:31:48,539 - INFO - Epoch 49/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:56<00:00,  3.04s/it]\n",
      "2024-07-15 21:38:45,496 - INFO - Epoch 49 - Train Loss: 0.2956, Train mIoU: 0.6980, Train Pixel Acc: 0.8510, Train Dice: 0.7512\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 21:40:42,338 - INFO - Epoch 49 - Val Loss: 0.3321, Val mIoU: 0.6906, Val Pixel Acc: 0.8414, Val Dice: 0.7433\n",
      "2024-07-15 21:40:42,338 - INFO - Current learning rate: 0.001597\n",
      "2024-07-15 21:40:42,338 - INFO - Epoch 50/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 21:47:41,870 - INFO - Epoch 50 - Train Loss: 0.2942, Train mIoU: 0.7044, Train Pixel Acc: 0.8508, Train Dice: 0.7585\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 21:49:38,620 - INFO - Epoch 50 - Val Loss: 0.3205, Val mIoU: 0.7004, Val Pixel Acc: 0.8423, Val Dice: 0.7528\n",
      "2024-07-15 21:49:39,176 - INFO - Epoch 50 - Best model saved with mIoU: 0.7004\n",
      "2024-07-15 21:49:39,706 - INFO - Epoch 50 - Checkpoint saved\n",
      "2024-07-15 21:49:39,706 - INFO - Current learning rate: 0.001333\n",
      "2024-07-15 21:49:39,706 - INFO - Epoch 51/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 21:56:40,192 - INFO - Epoch 51 - Train Loss: 0.2886, Train mIoU: 0.7034, Train Pixel Acc: 0.8532, Train Dice: 0.7580\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 21:58:37,224 - INFO - Epoch 51 - Val Loss: 0.3184, Val mIoU: 0.7060, Val Pixel Acc: 0.8453, Val Dice: 0.7591\n",
      "2024-07-15 21:58:37,735 - INFO - Epoch 51 - Best model saved with mIoU: 0.7060\n",
      "2024-07-15 21:58:37,735 - INFO - Current learning rate: 0.001089\n",
      "2024-07-15 21:58:37,735 - INFO - Epoch 52/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 22:05:37,613 - INFO - Epoch 52 - Train Loss: 0.2841, Train mIoU: 0.7098, Train Pixel Acc: 0.8539, Train Dice: 0.7646\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 22:07:34,100 - INFO - Epoch 52 - Val Loss: 0.3163, Val mIoU: 0.7045, Val Pixel Acc: 0.8486, Val Dice: 0.7573\n",
      "2024-07-15 22:07:34,100 - INFO - Current learning rate: 0.000868\n",
      "2024-07-15 22:07:34,100 - INFO - Epoch 53/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:02<00:00,  3.09s/it]\n",
      "2024-07-15 22:14:36,786 - INFO - Epoch 53 - Train Loss: 0.2798, Train mIoU: 0.7129, Train Pixel Acc: 0.8557, Train Dice: 0.7677\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 22:16:33,698 - INFO - Epoch 53 - Val Loss: 0.3248, Val mIoU: 0.7044, Val Pixel Acc: 0.8440, Val Dice: 0.7577\n",
      "2024-07-15 22:16:33,698 - INFO - Current learning rate: 0.000669\n",
      "2024-07-15 22:16:33,698 - INFO - Epoch 54/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:56<00:00,  3.04s/it]\n",
      "2024-07-15 22:23:30,307 - INFO - Epoch 54 - Train Loss: 0.2791, Train mIoU: 0.7107, Train Pixel Acc: 0.8566, Train Dice: 0.7656\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 22:25:27,129 - INFO - Epoch 54 - Val Loss: 0.3206, Val mIoU: 0.7073, Val Pixel Acc: 0.8459, Val Dice: 0.7604\n",
      "2024-07-15 22:25:27,637 - INFO - Epoch 54 - Best model saved with mIoU: 0.7073\n",
      "2024-07-15 22:25:27,637 - INFO - Current learning rate: 0.000494\n",
      "2024-07-15 22:25:27,637 - INFO - Epoch 55/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:59<00:00,  3.06s/it]\n",
      "2024-07-15 22:32:26,739 - INFO - Epoch 55 - Train Loss: 0.2746, Train mIoU: 0.7166, Train Pixel Acc: 0.8578, Train Dice: 0.7716\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.00s/it]\n",
      "2024-07-15 22:34:23,765 - INFO - Epoch 55 - Val Loss: 0.3210, Val mIoU: 0.7092, Val Pixel Acc: 0.8464, Val Dice: 0.7627\n",
      "2024-07-15 22:34:24,306 - INFO - Epoch 55 - Best model saved with mIoU: 0.7092\n",
      "2024-07-15 22:34:24,836 - INFO - Epoch 55 - Checkpoint saved\n",
      "2024-07-15 22:34:24,841 - INFO - Current learning rate: 0.000345\n",
      "2024-07-15 22:34:24,841 - INFO - Epoch 56/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [06:58<00:00,  3.06s/it]\n",
      "2024-07-15 22:41:23,697 - INFO - Epoch 56 - Train Loss: 0.2738, Train mIoU: 0.7164, Train Pixel Acc: 0.8580, Train Dice: 0.7714\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 22:43:20,615 - INFO - Epoch 56 - Val Loss: 0.3223, Val mIoU: 0.7086, Val Pixel Acc: 0.8468, Val Dice: 0.7615\n",
      "2024-07-15 22:43:20,616 - INFO - Current learning rate: 0.000222\n",
      "2024-07-15 22:43:20,616 - INFO - Epoch 57/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 22:50:22,122 - INFO - Epoch 57 - Train Loss: 0.2716, Train mIoU: 0.7198, Train Pixel Acc: 0.8585, Train Dice: 0.7751\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  3.00s/it]\n",
      "2024-07-15 22:52:19,054 - INFO - Epoch 57 - Val Loss: 0.3219, Val mIoU: 0.7087, Val Pixel Acc: 0.8486, Val Dice: 0.7611\n",
      "2024-07-15 22:52:19,064 - INFO - Current learning rate: 0.000125\n",
      "2024-07-15 22:52:19,064 - INFO - Epoch 58/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:00<00:00,  3.07s/it]\n",
      "2024-07-15 22:59:19,571 - INFO - Epoch 58 - Train Loss: 0.2703, Train mIoU: 0.7184, Train Pixel Acc: 0.8592, Train Dice: 0.7737\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:56<00:00,  2.99s/it]\n",
      "2024-07-15 23:01:16,333 - INFO - Epoch 58 - Val Loss: 0.3202, Val mIoU: 0.7096, Val Pixel Acc: 0.8478, Val Dice: 0.7625\n",
      "2024-07-15 23:01:16,928 - INFO - Epoch 58 - Best model saved with mIoU: 0.7096\n",
      "2024-07-15 23:01:16,928 - INFO - Current learning rate: 0.000056\n",
      "2024-07-15 23:01:16,928 - INFO - Epoch 59/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 23:08:18,236 - INFO - Epoch 59 - Train Loss: 0.2703, Train mIoU: 0.7194, Train Pixel Acc: 0.8595, Train Dice: 0.7748\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.01s/it]\n",
      "2024-07-15 23:10:15,752 - INFO - Epoch 59 - Val Loss: 0.3219, Val mIoU: 0.7090, Val Pixel Acc: 0.8460, Val Dice: 0.7625\n",
      "2024-07-15 23:10:15,752 - INFO - Current learning rate: 0.000014\n",
      "2024-07-15 23:10:15,752 - INFO - Epoch 60/60\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 137/137 [07:01<00:00,  3.08s/it]\n",
      "2024-07-15 23:17:17,263 - INFO - Epoch 60 - Train Loss: 0.2691, Train mIoU: 0.7197, Train Pixel Acc: 0.8597, Train Dice: 0.7749\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [01:57<00:00,  3.01s/it]\n",
      "2024-07-15 23:19:14,580 - INFO - Epoch 60 - Val Loss: 0.3225, Val mIoU: 0.7095, Val Pixel Acc: 0.8471, Val Dice: 0.7627\n",
      "2024-07-15 23:19:15,113 - INFO - Epoch 60 - Checkpoint saved\n",
      "2024-07-15 23:19:15,113 - INFO - Current learning rate: 0.000000\n",
      "2024-07-15 23:19:15,113 - INFO - Training completed after 60 epochs.\n",
      "2024-07-15 23:19:15,121 - INFO - Training and prediction completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from data_load import EnhancedWildScenesDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from utils.metrics import calculate_miou_train, calculate_pixel_accuracy, calculate_dice_coefficient\n",
    "from utils.losses import CombinedLoss\n",
    "from models.custom_deeplabv3 import CustomDeepLabV3\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scheduler, device, num_classes, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_miou = 0\n",
    "    total_pixel_acc = 0\n",
    "    total_dice = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['out'] if isinstance(outputs, dict) else outputs\n",
    "\n",
    "            if len(labels.shape) == 4 and labels.shape[1] > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            if outputs.shape[2:] != labels.shape[1:]:\n",
    "                outputs = F.interpolate(outputs, size=labels.shape[1:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        miou = calculate_miou_train(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "        pixel_acc = calculate_pixel_accuracy(pred.cpu().numpy(), labels.cpu().numpy())\n",
    "        dice = calculate_dice_coefficient(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "\n",
    "        if not np.isnan(miou):\n",
    "            total_miou += miou\n",
    "            total_pixel_acc += pixel_acc\n",
    "            total_dice += dice\n",
    "            num_batches += 1\n",
    "\n",
    "    return (total_loss / len(dataloader),\n",
    "            total_miou / num_batches if num_batches > 0 else 0.0,\n",
    "            total_pixel_acc / num_batches if num_batches > 0 else 0.0,\n",
    "            total_dice / num_batches if num_batches > 0 else 0.0)\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device, num_classes):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_miou = 0\n",
    "    total_pixel_acc = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['out'] if isinstance(outputs, dict) else outputs\n",
    "\n",
    "            if len(labels.shape) == 4 and labels.shape[1] > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            if outputs.shape[2:] != labels.shape[1:]:\n",
    "                outputs = F.interpolate(outputs, size=labels.shape[1:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            miou = calculate_miou_train(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "            pixel_acc = calculate_pixel_accuracy(pred.cpu().numpy(), labels.cpu().numpy())\n",
    "            dice = calculate_dice_coefficient(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "\n",
    "            total_miou += miou\n",
    "            total_pixel_acc += pixel_acc\n",
    "            total_dice += dice\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    return (total_loss / num_batches,\n",
    "            total_miou / num_batches,\n",
    "            total_pixel_acc / num_batches,\n",
    "            total_dice / num_batches)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, metrics, filename):\n",
    "    # 保存检查点\n",
    "    state = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def setup_logger(log_file):\n",
    "    # 设置日志记录器\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, save_dir, num_classes):\n",
    "    # 训练模型的主函数\n",
    "    best_miou = 0\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_epoch = epoch + 1\n",
    "        logging.info(f\"Epoch {current_epoch}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_miou, train_pixel_acc, train_dice = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scheduler, device, num_classes, scaler)\n",
    "        logging.info(f\"Epoch {current_epoch} - Train Loss: {train_loss:.4f}, Train mIoU: {train_miou:.4f}, \"\n",
    "                     f\"Train Pixel Acc: {train_pixel_acc:.4f}, Train Dice: {train_dice:.4f}\")\n",
    "\n",
    "        val_loss, val_miou, val_pixel_acc, val_dice = validate_epoch(\n",
    "            model, val_loader, criterion, device, num_classes)\n",
    "        logging.info(f\"Epoch {current_epoch} - Val Loss: {val_loss:.4f}, Val mIoU: {val_miou:.4f}, \"\n",
    "                     f\"Val Pixel Acc: {val_pixel_acc:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "\n",
    "        metrics = {\n",
    "            'miou': val_miou,\n",
    "            'pixel_acc': val_pixel_acc,\n",
    "            'dice': val_dice\n",
    "        }\n",
    "\n",
    "        if val_miou > best_miou:\n",
    "            best_miou = val_miou\n",
    "            best_model_path = os.path.join(save_dir, f'best_model_epoch_{current_epoch}.pth')\n",
    "            save_checkpoint(model, optimizer, current_epoch, metrics, best_model_path)\n",
    "            logging.info(f\"Epoch {current_epoch} - Best model saved with mIoU: {best_miou:.4f}\")\n",
    "\n",
    "        # if current_epoch % 5 == 0:\n",
    "        #     checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{current_epoch}.pth')\n",
    "        #     save_checkpoint(model, optimizer, current_epoch, metrics, checkpoint_path)\n",
    "        #     logging.info(f\"Epoch {current_epoch} - Checkpoint saved\")\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        logging.info(f\"Current learning rate: {current_lr:.6f}\")\n",
    "\n",
    "    logging.info(f\"Training completed after {num_epochs} epochs.\")\n",
    "    return best_model_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建保存目录\n",
    "    save_dir = os.path.join('model_checkpoints', 'DeepLabV3 ResNet 101')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 设置日志文件路径\n",
    "    log_file = os.path.join(save_dir, 'training.log')\n",
    "    setup_logger(log_file)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    train_loader = EnhancedWildScenesDataset.get_data_loader('train', batch_size=16)\n",
    "    val_loader = EnhancedWildScenesDataset.get_data_loader('valid', batch_size=16)\n",
    "\n",
    "    # test_loader = EnhancedWildScenesDataset.get_data_loader('test', batch_size=8)\n",
    "\n",
    "    num_classes = 17\n",
    "\n",
    "    # 选择模型\n",
    "    model = CustomDeepLabV3(num_classes=num_classes).to(device)\n",
    "\n",
    "    # 选择损失函数\n",
    "    # criterion = FocalLoss(alpha=1, gamma=2)\n",
    "    criterion = CombinedLoss(weight_focal=1.0, weight_dice=0.5)\n",
    "\n",
    "    # 选择优化器\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "    num_epochs = 60\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=0.01,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=num_epochs,\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25,\n",
    "        final_div_factor=1000\n",
    "    )\n",
    "\n",
    "    best_model_path = train(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                            num_epochs, device, save_dir, num_classes)\n",
    "\n",
    "    logging.info(\"Training and prediction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed71b5c-777b-4a12-b8ac-a6e485056412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:58:18,353 - INFO - Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:58:20,109 - INFO - Loaded model from model_checkpoints/DeepLabV3 ResNet 101/best_model_epoch_20.pth\n",
      "Testing:   0%|          | 0/35 [00:00<?, ?it/s]2024-07-22 02:58:26,976 - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Testing:  29%|██▊       | 10/35 [01:00<02:27,  5.91s/it]2024-07-22 02:59:26,259 - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Testing:  57%|█████▋    | 20/35 [01:59<01:27,  5.87s/it]2024-07-22 03:00:25,236 - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Testing:  86%|████████▌ | 30/35 [02:58<00:29,  5.91s/it]2024-07-22 03:01:24,427 - WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Testing: 100%|██████████| 35/35 [03:27<00:00,  5.94s/it]\n",
      "2024-07-22 03:01:47,972 - INFO - Test Results:\n",
      "2024-07-22 03:01:47,973 - INFO - Mean IoU: 0.4199\n",
      "2024-07-22 03:01:47,974 - INFO - Pixel Accuracy: 0.8244\n",
      "2024-07-22 03:01:47,975 - INFO - Dice Coefficient: 0.7097\n",
      "2024-07-22 03:01:47,976 - INFO - Per-class IoU:\n",
      "2024-07-22 03:01:47,977 - INFO - Class 0: 0.8110\n",
      "2024-07-22 03:01:47,978 - INFO - Class 1: nan\n",
      "2024-07-22 03:01:47,978 - INFO - Class 2: nan\n",
      "2024-07-22 03:01:47,979 - INFO - Class 3: nan\n",
      "2024-07-22 03:01:47,982 - INFO - Class 4: nan\n",
      "2024-07-22 03:01:47,983 - INFO - Class 5: 0.4309\n",
      "2024-07-22 03:01:47,984 - INFO - Class 6: 0.7979\n",
      "2024-07-22 03:01:47,985 - INFO - Class 7: nan\n",
      "2024-07-22 03:01:47,985 - INFO - Class 8: nan\n",
      "2024-07-22 03:01:47,988 - INFO - Class 9: nan\n",
      "2024-07-22 03:01:47,988 - INFO - Class 10: nan\n",
      "2024-07-22 03:01:47,989 - INFO - Class 11: nan\n",
      "2024-07-22 03:01:47,990 - INFO - Class 12: 0.2174\n",
      "2024-07-22 03:01:47,991 - INFO - Class 13: 0.0781\n",
      "2024-07-22 03:01:47,992 - INFO - Class 14: 0.6339\n",
      "2024-07-22 03:01:47,993 - INFO - Class 15: nan\n",
      "2024-07-22 03:01:47,994 - INFO - Class 16: 0.6757\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_load import EnhancedWildScenesDataset\n",
    "from models.custom_deeplabv3 import CustomDeepLabV3\n",
    "from utils.metrics import calculate_miou, calculate_pixel_accuracy, calculate_dice_coefficient\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def setup_logger(log_file):\n",
    "    os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_file),\n",
    "                            logging.StreamHandler()\n",
    "                        ])\n",
    "\n",
    "\n",
    "def save_comparison(image, ground_truth, prediction, index, save_dir):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    ax1.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(ground_truth.cpu().numpy())\n",
    "    ax2.set_title('Ground Truth')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.imshow(prediction.cpu().numpy())\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'comparison_{index}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def test(model, dataloader, device, num_classes, save_dir):\n",
    "    model.eval()\n",
    "    total_miou = 0\n",
    "    total_pixel_acc = 0\n",
    "    total_dice = 0\n",
    "    class_iou = np.zeros(num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=\"Testing\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['out'] if isinstance(outputs, dict) else outputs\n",
    "\n",
    "            if len(labels.shape) == 4 and labels.shape[1] > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            if outputs.shape[2:] != labels.shape[1:]:\n",
    "                outputs = F.interpolate(outputs, size=labels.shape[1:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            miou, class_iou_batch = calculate_miou(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "            pixel_acc = calculate_pixel_accuracy(pred.cpu().numpy(), labels.cpu().numpy())\n",
    "            dice = calculate_dice_coefficient(pred.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "\n",
    "            total_miou += miou\n",
    "            total_pixel_acc += pixel_acc\n",
    "            total_dice += dice\n",
    "            class_iou += class_iou_batch\n",
    "\n",
    "            if i % 10 == 0:  # Save every 10th image\n",
    "                save_comparison(images[0], labels[0], pred[0], i, save_dir)\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    avg_miou = total_miou / num_batches\n",
    "    avg_pixel_acc = total_pixel_acc / num_batches\n",
    "    avg_dice = total_dice / num_batches\n",
    "    avg_class_iou = class_iou / num_batches\n",
    "\n",
    "    return avg_miou, avg_pixel_acc, avg_dice, avg_class_iou\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = 'prediction/DeepLabV3_Resnet101'\n",
    "    log_file = os.path.join(save_dir, 'testing.log')\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    setup_logger(log_file)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    test_loader = EnhancedWildScenesDataset.get_data_loader('test', batch_size=8)\n",
    "\n",
    "    num_classes = 17\n",
    "\n",
    "    model = CustomDeepLabV3(num_classes=num_classes).to(device)\n",
    "\n",
    "    best_model_path = os.path.join('model_checkpoints', 'DeepLabV3 ResNet 101', 'best_model_epoch_20.pth')\n",
    "\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        logging.info(f\"Loaded model from {best_model_path}\")\n",
    "    else:\n",
    "        logging.error(f\"Model file not found: {best_model_path}\")\n",
    "        exit(1)\n",
    "\n",
    "    miou, pixel_acc, dice, class_iou = test(model, test_loader, device, num_classes, save_dir)\n",
    "\n",
    "    logging.info(f\"Test Results:\")\n",
    "    logging.info(f\"Mean IoU: {miou:.4f}\")\n",
    "    logging.info(f\"Pixel Accuracy: {pixel_acc:.4f}\")\n",
    "    logging.info(f\"Dice Coefficient: {dice:.4f}\")\n",
    "\n",
    "    logging.info(\"Per-class IoU:\")\n",
    "    for i, iou in enumerate(class_iou):\n",
    "        logging.info(f\"Class {i}: {iou:.4f}\")\n",
    "\n",
    "    # 可视化每个类别的IoU\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(num_classes), class_iou)\n",
    "    plt.title('Per-class IoU')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.savefig(os.path.join(save_dir, 'per_class_iou.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8b2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample labels shape: torch.Size([8, 256, 256])\n",
      "Unique values in sample labels: tensor([ 0,  1,  2,  5,  6,  7, 11, 12, 13, 14, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing:   0%|          | 0/35 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:   3%|▎         | 1/35 [00:09<05:31,  9.75s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:   6%|▌         | 2/35 [00:18<05:00,  9.10s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:   9%|▊         | 3/35 [00:27<04:51,  9.11s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  11%|█▏        | 4/35 [00:36<04:38,  8.99s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  14%|█▍        | 5/35 [00:44<04:25,  8.86s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  17%|█▋        | 6/35 [00:53<04:17,  8.88s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  20%|██        | 7/35 [01:02<04:07,  8.86s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  23%|██▎       | 8/35 [01:11<03:57,  8.81s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  26%|██▌       | 9/35 [01:20<03:51,  8.89s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  29%|██▊       | 10/35 [01:29<03:42,  8.91s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  31%|███▏      | 11/35 [01:38<03:33,  8.88s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  34%|███▍      | 12/35 [01:47<03:25,  8.92s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  37%|███▋      | 13/35 [01:56<03:19,  9.06s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  40%|████      | 14/35 [02:05<03:08,  8.98s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  43%|████▎     | 15/35 [02:14<02:59,  8.96s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  46%|████▌     | 16/35 [02:22<02:48,  8.86s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  49%|████▊     | 17/35 [02:31<02:39,  8.84s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  51%|█████▏    | 18/35 [02:41<02:33,  9.01s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  54%|█████▍    | 19/35 [02:49<02:23,  8.95s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  57%|█████▋    | 20/35 [02:58<02:13,  8.92s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  60%|██████    | 21/35 [03:07<02:04,  8.89s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  63%|██████▎   | 22/35 [03:16<01:55,  8.86s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  66%|██████▌   | 23/35 [03:25<01:46,  8.91s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  69%|██████▊   | 24/35 [03:35<01:43,  9.36s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  71%|███████▏  | 25/35 [03:45<01:32,  9.30s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  74%|███████▍  | 26/35 [03:54<01:23,  9.23s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  77%|███████▋  | 27/35 [04:03<01:13,  9.17s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  80%|████████  | 28/35 [04:12<01:03,  9.14s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  83%|████████▎ | 29/35 [04:21<00:54,  9.11s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  86%|████████▌ | 30/35 [04:30<00:45,  9.12s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  89%|████████▊ | 31/35 [04:40<00:37,  9.45s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  91%|█████████▏| 32/35 [04:49<00:28,  9.34s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  94%|█████████▍| 33/35 [04:58<00:18,  9.24s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing:  97%|█████████▋| 34/35 [05:07<00:09,  9.17s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Visualizing: 100%|██████████| 35/35 [05:16<00:00,  9.05s/it]\n",
      "/tmp/ipykernel_35491/2928478435.py:149: RuntimeWarning: invalid value encountered in true_divide\n",
      "  average_ious = np.where(class_counts > 0, all_class_ious / class_counts, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IoUs:\n",
      "Class 0 (Dirt): 0.7203\n",
      "Class 1 (Bush): 0.0000\n",
      "Class 2 (Fence): 0.4876\n",
      "Class 3 (Gravel): 0.0921\n",
      "Class 4 (Water): 0.0000\n",
      "Class 5 (Tree-trunk): 0.3720\n",
      "Class 6 (Tree-Foliage): 0.7955\n",
      "Class 7 (Other-object): 0.0123\n",
      "Class 8 (Other-terrain): 0.0000\n",
      "Class 9 (Rock): 0.1165\n",
      "Class 10 (Ignore): 0.0000\n",
      "Class 11 (Structure): 0.2892\n",
      "Class 12 (Mud): 0.1223\n",
      "Class 13 (Log): 0.0530\n",
      "Class 14 (Grass): 0.6002\n",
      "Class 15 (Background): 0.0000\n",
      "Class 16 (Sky): 0.4857\n",
      "Mean IoU: 0.2439\n",
      "Image-wise class IoUs saved to visualization_results/DeepLabV3_Resnet101/image_class_ious.csv\n",
      "Visualization results and IoU statistics saved in visualization_results/DeepLabV3_Resnet101\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from data_load import EnhancedWildScenesDataset\n",
    "from models.custom_deeplabv3 import CustomDeepLabV3\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# 定义颜色映射\n",
    "color_map = {\n",
    "    1: [224, 31, 77],  # Bush\n",
    "    0: [64, 180, 78],  # Dirt\n",
    "    2: [26, 127, 127],  # Fence\n",
    "    14: [127, 127, 127],  # Grass\n",
    "    3: [145, 24, 178],  # Gravel\n",
    "    13: [125, 128, 16],  # Log\n",
    "    12: [251, 225, 48],  # Mud\n",
    "    7: [248, 190, 190],  # Other-object\n",
    "    8: [89, 239, 239],  # Other-terrain\n",
    "    9: [173, 255, 196],  # Rock\n",
    "    16: [19, 0, 126],  # Sky\n",
    "    11: [167, 110, 44],  # Structure\n",
    "    6: [208, 245, 71],  # Tree-foliage\n",
    "    5: [238, 47, 227],  # Tree-trunk\n",
    "    4: [40, 127, 198],  # Water\n",
    "    15: [0, 0, 0],  # 背景类（黑色）\n",
    "    10: [128, 128, 128],  # 忽略类（灰色）\n",
    "}\n",
    "\n",
    "class_names = ['Dirt', 'Bush', 'Fence', 'Gravel', 'Water', 'Tree-trunk', 'Tree-Foliage', 'Other-object',\n",
    "               'Other-terrain', 'Rock', 'Ignore', 'Structure', 'Mud', 'Log', 'Grass', 'Background', 'Sky']\n",
    "\n",
    "\n",
    "def apply_color_map(segmentation):\n",
    "    color_segmentation = np.zeros((*segmentation.shape, 3), dtype=np.uint8)\n",
    "    for class_idx, color in color_map.items():\n",
    "        color_segmentation[segmentation == class_idx] = color\n",
    "    return color_segmentation\n",
    "\n",
    "\n",
    "def overlay_segmentation(image, segmentation, alpha=0.5):\n",
    "    colored_seg = apply_color_map(segmentation)\n",
    "    return (image * (1 - alpha) + colored_seg * alpha).astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_comparison(image, ground_truth, prediction, index, save_dir):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    ax1.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(apply_color_map(ground_truth.cpu().numpy()))\n",
    "    ax2.set_title('Ground Truth')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.imshow(apply_color_map(prediction.cpu().numpy()))\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    ax4.imshow(overlay_segmentation(image.permute(1, 2, 0).cpu().numpy(), prediction.cpu().numpy()))\n",
    "    ax4.set_title('Overlay')\n",
    "    ax4.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'comparison_{index}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_per_class_iou(class_iou, save_path):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    valid_iou = [iou for iou in class_iou if not np.isnan(iou)]\n",
    "    plt.bar(range(len(valid_iou)), valid_iou)\n",
    "    plt.title('Per-class IoU')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('IoU')\n",
    "    valid_class_names = [name for i, name in enumerate(class_names) if i < len(valid_iou)]\n",
    "    plt.xticks(range(len(valid_iou)), valid_class_names, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def calculate_miou(pred, target, num_classes):\n",
    "    ious = []\n",
    "    pred = pred.ravel()\n",
    "    target = target.ravel()\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = np.logical_and(pred_inds, target_inds).sum()\n",
    "        union = np.logical_or(pred_inds, target_inds).sum()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # 如果该类别不存在，则IoU为NaN\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    miou = np.nanmean(ious)  # 忽略NaN值计算平均IoU\n",
    "    return miou, np.array(ious)\n",
    "\n",
    "\n",
    "def visualize_results(model, dataloader, device, num_classes, save_dir):\n",
    "    model.eval()\n",
    "    all_class_ious = np.zeros(num_classes)\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    image_ious = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=\"Visualizing\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['out'] if isinstance(outputs, dict) else outputs\n",
    "\n",
    "            if len(labels.shape) == 4 and labels.shape[1] > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            if outputs.shape[2:] != labels.shape[1:]:\n",
    "                outputs = F.interpolate(outputs, size=labels.shape[1:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 计算每张图片的IoU\n",
    "            for j in range(images.shape[0]):\n",
    "                image_index = i * dataloader.batch_size + j\n",
    "                _, class_ious = calculate_miou(pred[j].cpu().numpy(), labels[j].cpu().numpy(), num_classes)\n",
    "                all_class_ious += np.nan_to_num(class_ious)  # 将NaN转换为0\n",
    "                class_counts += ~np.isnan(class_ious)  # 统计非NaN值的数量\n",
    "                image_ious.append(class_ious)\n",
    "\n",
    "                # 保存每张图片的可视化结果\n",
    "                save_comparison(images[j], labels[j], pred[j], image_index, save_dir)\n",
    "\n",
    "    # 计算平均IoU\n",
    "    average_ious = np.where(class_counts > 0, all_class_ious / class_counts, 0)\n",
    "\n",
    "    print(\"Class IoUs:\")\n",
    "    for cls, iou in enumerate(average_ious):\n",
    "        print(f\"Class {cls} ({class_names[cls]}): {iou:.4f}\")\n",
    "\n",
    "    # 绘制每类IoU图\n",
    "    plot_per_class_iou(average_ious, os.path.join(save_dir, 'per_class_iou.png'))\n",
    "\n",
    "    # 计算mIoU\n",
    "    miou = np.mean(average_ious)\n",
    "    print(f\"Mean IoU: {miou:.4f}\")\n",
    "\n",
    "    # 创建并保存CSV文件\n",
    "    csv_file = os.path.join(save_dir, 'image_class_ious.csv')\n",
    "    df = pd.DataFrame(image_ious, columns=[f\"{cls}_{name}\" for cls, name in enumerate(class_names)])\n",
    "    df.index.name = 'Image_Number'\n",
    "    df.to_csv(csv_file)\n",
    "    print(f\"Image-wise class IoUs saved to {csv_file}\")\n",
    "\n",
    "    return average_ious, miou\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置保存目录\n",
    "    save_dir = 'visualization_results/DeepLabV3_Resnet101'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 加载模型和数据\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_classes = 17\n",
    "\n",
    "    # 创建模型实例\n",
    "    model = CustomDeepLabV3(num_classes=num_classes).to(device)\n",
    "\n",
    "    # 加载模型权重\n",
    "    model_path = os.path.join('model_checkpoints', 'DeepLabV3 ResNet 101', 'best_model_epoch_20.pth')\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # 确保模型处于评估模式\n",
    "    model.eval()\n",
    "\n",
    "    # 加载测试数据\n",
    "    test_loader = EnhancedWildScenesDataset.get_data_loader('test', batch_size=8)\n",
    "\n",
    "    # 打印一些样本数据\n",
    "    for images, labels in test_loader:\n",
    "        print(\"Sample labels shape:\", labels.shape)\n",
    "        print(\"Unique values in sample labels:\", torch.unique(labels))\n",
    "        break\n",
    "\n",
    "    # 运行可视化并获取结果\n",
    "    class_ious, miou = visualize_results(model, test_loader, device, num_classes, save_dir)\n",
    "\n",
    "    # 保存结果到文件\n",
    "    results_file = os.path.join(save_dir, 'iou_results.txt')\n",
    "    with open(results_file, 'w') as f:\n",
    "        f.write(f\"Mean IoU: {miou:.4f}\\n\\n\")\n",
    "        f.write(\"Class IoUs:\\n\")\n",
    "        for cls, iou in enumerate(class_ious):\n",
    "            f.write(f\"Class {cls} ({class_names[cls]}): {iou:.4f}\\n\")\n",
    "\n",
    "    print(f\"Visualization results and IoU statistics saved in {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
